{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载并可视化FashionMNIST\n",
    "---\n",
    "在这个notebook中，我们要加载并查看 [Fashion-MNIST 数据库](https://github.com/zalandoresearch/fashion-mnist)中的图像。\n",
    "\n",
    "任何分类问题的第一步，都是查看你正在使用的数据集。这样你可以了解有关图像和标签格式的一些详细信息，以及对如何定义网络以识别此类图像集中的模式的一些见解。\n",
    "\n",
    "PyTorch有一些你可以使用的内置数据集，而FashionMNIST就是其中之一，它已经下载到了这个notebook中的`data/`目录中，所以我们要做的就是使用FashionMNIST数据集类加载这些图像，并使用`DataLoader`批量加载数据。\n",
    "\n",
    "### 加载[数据](http://pytorch.org/docs/master/torchvision/datasets.html) \n",
    "\n",
    "#### 数据集类和张量\n",
    "\n",
    " ``torch.utils.data.Dataset``是一个表示数据集的抽象类，而 FashionMNIST类是这个数据集类的扩展，它可以让我们加载批量的图像/标签数据，并且统一地将变换应用于我们的数据，例如将所有图像转换为用于训练神经网络的张量。*张量类似于numpy数组，但也可以在GPU上使用，用来加速计算 。*\n",
    "\n",
    "下面，让我们看一看如何构建训练数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our basic libraries\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# data loading and transforming\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors for input into a CNN\n",
    "\n",
    "## Define a transform to read the data in as a tensor\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = FashionMNIST(root='./data', train=True,\n",
    "                                   download=False, transform=data_transform)\n",
    "\n",
    "# Print out some stats about the training data\n",
    "print('Train data, number of images: ', len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据迭代与批处理\n",
    "\n",
    "接下来，我们将要使用的是``torch.utils.data.DataLoader``，它是一个可以批量处理数据并置乱数据的迭代器。\n",
    "\n",
    "在下一个单元格中，我们将数据置乱，并以大小为20的批量加载图像/标签数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders, set the batch_size\n",
    "## TODO: you can try changing the batch_size to be larger or smaller\n",
    "## when you get to training your network, see how batch_size affects the loss\n",
    "batch_size = 20\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将一些训练数据可视化\n",
    "\n",
    "这个单元格会遍历该训练数据集，并使用`dataiter.next()`加载一个随机批次的图像/标签数据。然后，它会在`2 x batch_size/2`网格中将这批图像和标签可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更详细地查看图像\n",
    "\n",
    "该数据集中的每个图像都是`28x28`像素且已归一化的灰度图像。\n",
    "\n",
    "#### 关于归一化的说明\n",
    "\n",
    "归一化可以确保在训练CNN的过程中，先后经历前馈与反向传播步骤时，每个图像特征都将落入类似的值范围内，而不是过度激活该网络中的特定层。在前馈步骤期间，该神经网络会接收输入图像并将每个输入像素乘以一些卷积滤波器权重并加上偏差，然后应用一些激活和池化函数。如果没有归一化，反向传播步骤中的计算梯度将会非常大，并且会导致我们的损失增加而不是收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an image by index\n",
    "idx = 2\n",
    "img = np.squeeze(images[idx])\n",
    "\n",
    "# display the pixel values in that image\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "width, height = img.shape\n",
    "thresh = img.max()/2.5\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "        ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
